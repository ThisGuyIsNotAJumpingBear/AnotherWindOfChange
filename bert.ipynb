{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from utils import get_sorted_tweets, get_target_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name).cuda()\n",
    "tweets = get_sorted_tweets()\n",
    "target_words = get_target_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frisk',\n",
       " 'impostor',\n",
       " 'containment',\n",
       " 'gala',\n",
       " 'recount',\n",
       " 'lotte',\n",
       " 'pogrom',\n",
       " 'parasol',\n",
       " 'pyre',\n",
       " 'milker',\n",
       " 'launchpad',\n",
       " 'vanguard',\n",
       " 'airdrop',\n",
       " 'ventilator',\n",
       " 'villager',\n",
       " 'primo',\n",
       " 'delta',\n",
       " 'epicenter',\n",
       " 'burnham',\n",
       " 'bullpen',\n",
       " 'virus',\n",
       " 'turnip',\n",
       " 'monet',\n",
       " 'mask',\n",
       " 'crt',\n",
       " 'ido',\n",
       " 'unlabeled',\n",
       " 'teargas',\n",
       " 'gaza',\n",
       " 'folklore',\n",
       " 'entanglement',\n",
       " 'paternity',\n",
       " 'bunker',\n",
       " 'moxie']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vector_from_context(word, text):\n",
    "    tok_w = tokenizer(word, return_tensors='pt', add_special_tokens=False)\n",
    "    tok = int(tok_w['input_ids'].flatten()[0])\n",
    "    len_tok = len(tok_w['input_ids'].flatten())\n",
    "    tok_t = tokenizer(text, return_tensors='pt', padding='max_length')\n",
    "    ids = tok_t['input_ids'].flatten().tolist()\n",
    "    if tok in ids:\n",
    "        idx = ids.index(tok)\n",
    "    else:\n",
    "        raise ValueError(f'{tok} from {tok_w} not in list {ids}. \\n text: {text} word {word} \\n tokenizer decode: {tokenizer.decode(ids)}')\n",
    "    for item in tok_t:\n",
    "        tok_t[item] = tok_t[item].to('cuda')\n",
    "    vec = model(**tok_t)['last_hidden_state'].squeeze(0)[idx:idx+len_tok].cpu().detach().numpy()\n",
    "    vec = np.average(vec, axis=0)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_vector_by_year(year):\n",
    "    target_word_vectors = {wrd: [] for wrd in target_words}\n",
    "    data = tweets[year]\n",
    "    for t in data:\n",
    "        word = t['word']\n",
    "        text = t['text']\n",
    "        try:\n",
    "            vec = generate_vector_from_context(word, text)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        target_word_vectors[word].append(vec)\n",
    "    for wrd in target_words:\n",
    "        vecs = np.array(target_word_vectors[wrd])\n",
    "        target_word_vectors[wrd] = np.average(vecs, axis=0)\n",
    "\n",
    "    return target_word_vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ROG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\ROG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "vecs = avg_vector_by_year('2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, labels_path):\n",
    "    # Load tweet instances\n",
    "    with open(data_path, 'r', encoding='utf-8') as file:\n",
    "        data_instances = [json.loads(line) for line in file]\n",
    "\n",
    "    # Load labels\n",
    "    with open(labels_path, 'r', encoding='utf-8') as file:\n",
    "        labels = dict(line.strip().split('\\t') for line in file)\n",
    "\n",
    "    return data_instances, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "train_data_path = 'data/train.data.jl'\n",
    "train_labels_path = 'data/train.labels.tsv'\n",
    "\n",
    "# Load data\n",
    "data_instances, labels = load_data(train_data_path, train_labels_path)\n",
    "\n",
    "pairs = {item['id']: [item['tweet1']['text'], item['tweet2']['text'], item['word']] for item in data_instances}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_acc(threshold):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for key in pairs:\n",
    "        label = labels[key]\n",
    "        t1, t2, word = pairs[key]\n",
    "        try:\n",
    "            vec1 = generate_vector_from_context(word, t1)\n",
    "            vec2 = generate_vector_from_context(word, t2)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        res = float(cosine_similarity([vec1], [vec2]).flatten()[0])\n",
    "        res = 1 if res > threshold else 0\n",
    "        if res == int(label):\n",
    "            correct += 1\n",
    "        count += 1\n",
    "\n",
    "    return correct / count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45646067415730335\n",
      "0.45646067415730335\n",
      "0.45646067415730335\n",
      "0.45646067415730335\n",
      "0.46348314606741575\n",
      "0.4768258426966292\n",
      "0.5344101123595506\n",
      "0.6587078651685393\n",
      "0.613061797752809\n",
      "0.5484550561797753\n"
     ]
    }
   ],
   "source": [
    "for threshold in range(10):\n",
    "    i = threshold / 10\n",
    "    print(find_acc(i))\n",
    "# best threshold 0.7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
