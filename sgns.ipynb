{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pickle\n",
    "from utils import get_sorted_tweets, get_target_words, load_annotator_labels\n",
    "import gensim\n",
    "from procrustes import orthogonal\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from utils import get_target_words\n",
    "from scipy.stats import pearsonr\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgns hyperparameters\n",
    "k_lst = [5, 7, 10, 12, 15]\n",
    "vector_size_lst = [100, 200, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 5 vector_size: 100 year: 2019: Word2Vec<vocab=1271, vector_size=100, alpha=0.025>\n",
      "k: 5 vector_size: 100 year: 2020: Word2Vec<vocab=8861, vector_size=100, alpha=0.025>\n",
      "k: 5 vector_size: 100 year: 2021: Word2Vec<vocab=7591, vector_size=100, alpha=0.025>\n",
      "k: 5 vector_size: 200 year: 2019: Word2Vec<vocab=1271, vector_size=200, alpha=0.025>\n",
      "k: 5 vector_size: 200 year: 2020: Word2Vec<vocab=8861, vector_size=200, alpha=0.025>\n",
      "k: 5 vector_size: 200 year: 2021: Word2Vec<vocab=7591, vector_size=200, alpha=0.025>\n",
      "k: 5 vector_size: 300 year: 2019: Word2Vec<vocab=1271, vector_size=300, alpha=0.025>\n",
      "k: 5 vector_size: 300 year: 2020: Word2Vec<vocab=8861, vector_size=300, alpha=0.025>\n",
      "k: 5 vector_size: 300 year: 2021: Word2Vec<vocab=7591, vector_size=300, alpha=0.025>\n",
      "k: 7 vector_size: 100 year: 2019: Word2Vec<vocab=1271, vector_size=100, alpha=0.025>\n",
      "k: 7 vector_size: 100 year: 2020: Word2Vec<vocab=8861, vector_size=100, alpha=0.025>\n",
      "k: 7 vector_size: 100 year: 2021: Word2Vec<vocab=7591, vector_size=100, alpha=0.025>\n",
      "k: 7 vector_size: 200 year: 2019: Word2Vec<vocab=1271, vector_size=200, alpha=0.025>\n",
      "k: 7 vector_size: 200 year: 2020: Word2Vec<vocab=8861, vector_size=200, alpha=0.025>\n",
      "k: 7 vector_size: 200 year: 2021: Word2Vec<vocab=7591, vector_size=200, alpha=0.025>\n",
      "k: 7 vector_size: 300 year: 2019: Word2Vec<vocab=1271, vector_size=300, alpha=0.025>\n",
      "k: 7 vector_size: 300 year: 2020: Word2Vec<vocab=8861, vector_size=300, alpha=0.025>\n",
      "k: 7 vector_size: 300 year: 2021: Word2Vec<vocab=7591, vector_size=300, alpha=0.025>\n",
      "k: 10 vector_size: 100 year: 2019: Word2Vec<vocab=1271, vector_size=100, alpha=0.025>\n",
      "k: 10 vector_size: 100 year: 2020: Word2Vec<vocab=8861, vector_size=100, alpha=0.025>\n",
      "k: 10 vector_size: 100 year: 2021: Word2Vec<vocab=7591, vector_size=100, alpha=0.025>\n",
      "k: 10 vector_size: 200 year: 2019: Word2Vec<vocab=1271, vector_size=200, alpha=0.025>\n",
      "k: 10 vector_size: 200 year: 2020: Word2Vec<vocab=8861, vector_size=200, alpha=0.025>\n",
      "k: 10 vector_size: 200 year: 2021: Word2Vec<vocab=7591, vector_size=200, alpha=0.025>\n",
      "k: 10 vector_size: 300 year: 2019: Word2Vec<vocab=1271, vector_size=300, alpha=0.025>\n",
      "k: 10 vector_size: 300 year: 2020: Word2Vec<vocab=8861, vector_size=300, alpha=0.025>\n",
      "k: 10 vector_size: 300 year: 2021: Word2Vec<vocab=7591, vector_size=300, alpha=0.025>\n",
      "k: 12 vector_size: 100 year: 2019: Word2Vec<vocab=1271, vector_size=100, alpha=0.025>\n",
      "k: 12 vector_size: 100 year: 2020: Word2Vec<vocab=8861, vector_size=100, alpha=0.025>\n",
      "k: 12 vector_size: 100 year: 2021: Word2Vec<vocab=7591, vector_size=100, alpha=0.025>\n",
      "k: 12 vector_size: 200 year: 2019: Word2Vec<vocab=1271, vector_size=200, alpha=0.025>\n",
      "k: 12 vector_size: 200 year: 2020: Word2Vec<vocab=8861, vector_size=200, alpha=0.025>\n",
      "k: 12 vector_size: 200 year: 2021: Word2Vec<vocab=7591, vector_size=200, alpha=0.025>\n",
      "k: 12 vector_size: 300 year: 2019: Word2Vec<vocab=1271, vector_size=300, alpha=0.025>\n",
      "k: 12 vector_size: 300 year: 2020: Word2Vec<vocab=8861, vector_size=300, alpha=0.025>\n",
      "k: 12 vector_size: 300 year: 2021: Word2Vec<vocab=7591, vector_size=300, alpha=0.025>\n",
      "k: 15 vector_size: 100 year: 2019: Word2Vec<vocab=1271, vector_size=100, alpha=0.025>\n",
      "k: 15 vector_size: 100 year: 2020: Word2Vec<vocab=8861, vector_size=100, alpha=0.025>\n",
      "k: 15 vector_size: 100 year: 2021: Word2Vec<vocab=7591, vector_size=100, alpha=0.025>\n",
      "k: 15 vector_size: 200 year: 2019: Word2Vec<vocab=1271, vector_size=200, alpha=0.025>\n",
      "k: 15 vector_size: 200 year: 2020: Word2Vec<vocab=8861, vector_size=200, alpha=0.025>\n",
      "k: 15 vector_size: 200 year: 2021: Word2Vec<vocab=7591, vector_size=200, alpha=0.025>\n",
      "k: 15 vector_size: 300 year: 2019: Word2Vec<vocab=1271, vector_size=300, alpha=0.025>\n",
      "k: 15 vector_size: 300 year: 2020: Word2Vec<vocab=8861, vector_size=300, alpha=0.025>\n",
      "k: 15 vector_size: 300 year: 2021: Word2Vec<vocab=7591, vector_size=300, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "date_dict = get_sorted_tweets()\n",
    "\n",
    "years = [\"2019\", \"2020\", \"2021\"]\n",
    "\n",
    "for k in k_lst:\n",
    "    for vector_size in vector_size_lst:\n",
    "        for year in years:\n",
    "\n",
    "            model = gensim.models.Word2Vec(\n",
    "                sg=1, # skipgram\n",
    "                hs=0, # negative sampling\n",
    "                negative=k, # number of negative samples\n",
    "                workers=4,\n",
    "                vector_size=vector_size\n",
    "            )\n",
    "            \n",
    "            sentence_list = []\n",
    "            data_year = date_dict[year]\n",
    "            for data in data_year:\n",
    "                sentence_list.append(data[\"tokens\"])\n",
    "\n",
    "            model.build_vocab(sentence_list)\n",
    "            model.train(sentence_list, total_examples=model.corpus_count, epochs=20)\n",
    "\n",
    "            print(f\"k: {k} vector_size: {vector_size} year: {year}: {model}\")\n",
    "\n",
    "            # # Save the vectors and the model\n",
    "            outpath = f'model_files/sngs_{year}_{k}_{vector_size}'\n",
    "            model.wv.save(outpath)\n",
    "            model.save(outpath + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_dist(v1, v2):\n",
    "    return 1 - metrics.pairwise.cosine_similarity(v1.reshape(1, -1), v2.reshape(1, -1))[0][0]\n",
    "\n",
    "def get_same_words(word_set1, word_set2):\n",
    "    return word_set1.intersection(word_set2)\n",
    "\n",
    "def create_matrices(word2vec1, word2vec2):\n",
    "    vocab1 = set(word2vec1.index_to_key)\n",
    "    vocab2 = set(word2vec2.index_to_key)\n",
    "\n",
    "    intersect = get_same_words(vocab1, vocab2)\n",
    "\n",
    "    mat1 = np.zeros((len(intersect), vector_size))\n",
    "    mat2 = np.zeros((len(intersect), vector_size))\n",
    "\n",
    "    for i, word in enumerate(intersect):\n",
    "        mat1[i] = word2vec1.get_vector(word)\n",
    "        mat2[i] = word2vec2.get_vector(word)\n",
    "    \n",
    "\n",
    "    return list(intersect), mat1, mat2\n",
    "\n",
    "def get_consine_distance(year1, year2, k, vector_size):\n",
    "    target_words = get_target_words()\n",
    "\n",
    "    word2vec_path1 = f\"model_files/sngs_{year1}_{k}_{vector_size}\"\n",
    "    word2vec_path2 = f\"model_files/sngs_{year2}_{k}_{vector_size}\"\n",
    "    word2vec1 = gensim.models.KeyedVectors.load(word2vec_path1)\n",
    "    word2vec2 = gensim.models.KeyedVectors.load(word2vec_path2)\n",
    "\n",
    "    intersect, mat1, mat2 = create_matrices(word2vec1, word2vec2)\n",
    "\n",
    "    result = orthogonal(mat1, mat2, scale=True, translate=True)\n",
    "    # display_procrutes_result(result)\n",
    "    a_op = np.dot(result.new_a, result.t)\n",
    "    cosine_distances = {}\n",
    "    for target in target_words:\n",
    "        try:\n",
    "            idx = intersect.index(target)\n",
    "            cosine_distances[target] = cosine_dist(a_op[idx], result.new_b[idx])\n",
    "        except:\n",
    "            pass\n",
    "            # print(f\"target word {target} is not found in the intersect of both corpora\")\n",
    "    \n",
    "    return cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161\n",
      "3119\n",
      "1161\n",
      "3119\n",
      "1161\n",
      "3119\n",
      "1161\n",
      "3119\n",
      "1161\n",
      "3119\n",
      "1161\n",
      "3119\n",
      "1161\n",
      "3119\n",
      "1161\n",
      "3119\n",
      "1161\n",
      "3119\n",
      "1161\n",
      "3119\n",
      "1161\n",
      "3119\n",
      "1161\n",
      "3119\n",
      "1161\n",
      "3119\n",
      "1161\n",
      "3119\n",
      "1161\n",
      "3119\n",
      "pearson coeff and p-value for k=10, vector_size=100: 0.36859002512970807\n",
      "pearson coeff and p-value for k=15, vector_size=100: 0.35634412780396263\n",
      "pearson coeff and p-value for k=12, vector_size=100: 0.3529861192859172\n",
      "pearson coeff and p-value for k=5, vector_size=100: 0.2844202672584794\n",
      "pearson coeff and p-value for k=10, vector_size=200: 0.23261616224768084\n",
      "pearson coeff and p-value for k=7, vector_size=100: 0.1690126681180513\n",
      "pearson coeff and p-value for k=15, vector_size=300: 0.16262132910649132\n",
      "pearson coeff and p-value for k=15, vector_size=200: 0.15944589431889106\n",
      "pearson coeff and p-value for k=12, vector_size=200: 0.15363872010872978\n",
      "pearson coeff and p-value for k=5, vector_size=300: 0.1533837356810638\n",
      "pearson coeff and p-value for k=7, vector_size=200: 0.13455327294557134\n",
      "pearson coeff and p-value for k=5, vector_size=200: 0.11380670615634197\n",
      "pearson coeff and p-value for k=10, vector_size=300: 0.10469818700353709\n",
      "pearson coeff and p-value for k=12, vector_size=300: 0.07885583414444082\n",
      "pearson coeff and p-value for k=7, vector_size=300: 0.07411377478575829\n",
      "--------------------------------------------------------------------------------\n",
      "all scores\n",
      "pearson coeff and p-value for k=5, vector_size=100, year=2019-2020: 0.2962667109474509, 0.21809547012034605\n",
      "pearson coeff and p-value for k=5, vector_size=100, year=2020-2021: 0.27257382356950793, 0.2898473992778332\n",
      "pearson coeff and p-value for k=5, vector_size=200, year=2019-2020: 0.22876093063516, 0.3461798036442094\n",
      "pearson coeff and p-value for k=5, vector_size=200, year=2020-2021: -0.0011475183224760495, 0.9965125244408102\n",
      "pearson coeff and p-value for k=5, vector_size=300, year=2019-2020: 0.2909162528475531, 0.22691757989380176\n",
      "pearson coeff and p-value for k=5, vector_size=300, year=2020-2021: 0.01585121851457451, 0.9518519126068254\n",
      "pearson coeff and p-value for k=7, vector_size=100, year=2019-2020: 0.33395195169063846, 0.16231128346393806\n",
      "pearson coeff and p-value for k=7, vector_size=100, year=2020-2021: 0.004073384545464137, 0.9876207999422414\n",
      "pearson coeff and p-value for k=7, vector_size=200, year=2019-2020: 0.2645398205757812, 0.27375134575326754\n",
      "pearson coeff and p-value for k=7, vector_size=200, year=2020-2021: 0.004566725315361536, 0.9861216431771587\n",
      "pearson coeff and p-value for k=7, vector_size=300, year=2019-2020: 0.24121469000304643, 0.3198132133952151\n",
      "pearson coeff and p-value for k=7, vector_size=300, year=2020-2021: -0.09298714043152986, 0.7226172334915065\n",
      "pearson coeff and p-value for k=10, vector_size=100, year=2019-2020: 0.528611460846618, 0.019973630054101077\n",
      "pearson coeff and p-value for k=10, vector_size=100, year=2020-2021: 0.20856858941279816, 0.421777323050361\n",
      "pearson coeff and p-value for k=10, vector_size=200, year=2019-2020: 0.36054044126499374, 0.1294171397813509\n",
      "pearson coeff and p-value for k=10, vector_size=200, year=2020-2021: 0.1046918832303679, 0.6892459967466662\n",
      "pearson coeff and p-value for k=10, vector_size=300, year=2019-2020: 0.2114538259263388, 0.3848363921496379\n",
      "pearson coeff and p-value for k=10, vector_size=300, year=2020-2021: -0.0020574519192646107, 0.9937471430268772\n",
      "pearson coeff and p-value for k=12, vector_size=100, year=2019-2020: 0.4601736177528566, 0.04742164161414729\n",
      "pearson coeff and p-value for k=12, vector_size=100, year=2020-2021: 0.24579862081897783, 0.3416249561844475\n",
      "pearson coeff and p-value for k=12, vector_size=200, year=2019-2020: 0.21145144766892968, 0.38484186290179834\n",
      "pearson coeff and p-value for k=12, vector_size=200, year=2020-2021: 0.09582599254852989, 0.7144772872600209\n",
      "pearson coeff and p-value for k=12, vector_size=300, year=2019-2020: 0.16683770730399763, 0.49481731764632214\n",
      "pearson coeff and p-value for k=12, vector_size=300, year=2020-2021: -0.009126039015116001, 0.972269561348233\n",
      "pearson coeff and p-value for k=15, vector_size=100, year=2019-2020: 0.3945786754067158, 0.09456453763229164\n",
      "pearson coeff and p-value for k=15, vector_size=100, year=2020-2021: 0.3181095802012094, 0.21337734570005776\n",
      "pearson coeff and p-value for k=15, vector_size=200, year=2019-2020: 0.20070159390431075, 0.4100082868152157\n",
      "pearson coeff and p-value for k=15, vector_size=200, year=2020-2021: 0.11819019473347134, 0.6514263689119332\n",
      "pearson coeff and p-value for k=15, vector_size=300, year=2019-2020: 0.25930562007826385, 0.28370863204438895\n",
      "pearson coeff and p-value for k=15, vector_size=300, year=2020-2021: 0.0659370381347188, 0.8014813738273123\n"
     ]
    }
   ],
   "source": [
    "years = [(\"2019\", \"2020\"), (\"2020\", \"2021\")]\n",
    "\n",
    "scores = []\n",
    "avg_scores = []\n",
    "\n",
    "for k in k_lst:\n",
    "    for vector_size in vector_size_lst:\n",
    "        total_pearson = 0\n",
    "        for year1, year2 in years:\n",
    "            cd = get_consine_distance(year1, year2, k, vector_size)\n",
    "            \n",
    "            labels = load_annotator_labels()\n",
    "\n",
    "            sgns_vec = []\n",
    "            annotator_vec = []\n",
    "\n",
    "            for key in cd.keys():\n",
    "                sgns_vec.append(float(cd[key]))\n",
    "                annotator_vec.append(float(labels[key]))\n",
    "\n",
    "            pearson, p_value = pearsonr(sgns_vec, annotator_vec)\n",
    "            total_pearson += pearson\n",
    "            scores.append((k, vector_size, pearson, p_value, year1, year2))\n",
    "        avg_scores.append((k, vector_size, total_pearson / 2))\n",
    "\n",
    "sorted_avg_scores = sorted(avg_scores, key=itemgetter(2), reverse=True)\n",
    "\n",
    "for score in sorted_avg_scores:\n",
    "    k, vector_size, pearson = score\n",
    "    print(f\"pearson coeff and p-value for k={k}, vector_size={vector_size}: {pearson}\")\n",
    "\n",
    "print('-' * 80)\n",
    "print(\"all scores\")\n",
    "for score_obj in scores:\n",
    "    k, vector_size, pearson, p_value, year1, year2 = score_obj\n",
    "    print(f\"pearson coeff and p-value for k={k}, vector_size={vector_size}, year={year1}-{year2}: {pearson}, {p_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9a902e6a5cf10f0266cd56ad91f8b2e66b295b7f56b43a091f5e49920b976f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
