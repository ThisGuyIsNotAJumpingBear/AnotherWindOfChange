{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "from nltk import bigrams\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from utils import get_sorted_tweets, get_target_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = get_sorted_tweets()\n",
    "target_words = get_target_words()\n",
    "\n",
    "tsv_file_path = 'data/annotator.tsv'\n",
    "\n",
    "# Read the TSV file into a pandas DataFrame\n",
    "df = pd.read_csv(tsv_file_path, sep=' ', header=None).to_numpy()\n",
    "annotator = {item[0]: item[1] for item in df}\n",
    "ground_truth = [annotator[word] for word in target_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppmi_by_year(year, dim):\n",
    "    tweets = get_sorted_tweets()\n",
    "    target_words = get_target_words()\n",
    "    tweets = tweets[str(year)]\n",
    "    words = []\n",
    "    for tweet in tweets:\n",
    "        words.extend(tweet['tokens'])\n",
    "\n",
    "    cnt = Counter(words)\n",
    "    common = [word[0] for word in cnt.most_common(2000)]\n",
    "    w = list(set(common)) + target_words\n",
    "    bigram_pairs = list(bigrams(words))\n",
    "    bigram_freq = FreqDist(bigram_pairs)\n",
    "    cooccur_matrix = np.zeros((len(w), len(w)))\n",
    "    for i in range(len(w)):\n",
    "        for j in range(len(w)):\n",
    "            freq = bigram_freq[(w[i], w[j])]\n",
    "            cooccur_matrix[i, j] = freq\n",
    "    total_occurrences = np.sum(cooccur_matrix)\n",
    "    row_sums = np.sum(cooccur_matrix, axis=1)\n",
    "    col_sums = np.sum(cooccur_matrix, axis=0)\n",
    "\n",
    "    ppmi_matrix = np.zeros_like(cooccur_matrix)\n",
    "\n",
    "    for i in range(cooccur_matrix.shape[0]):\n",
    "        for j in range(cooccur_matrix.shape[1]):\n",
    "            p_x_y = cooccur_matrix[i, j] / total_occurrences\n",
    "            p_x = row_sums[i] / total_occurrences\n",
    "            p_y = col_sums[j] / total_occurrences\n",
    "            \n",
    "            pmi = np.log2(p_x_y / (p_x * p_y + 1e-15) + 1e-15)\n",
    "            if pmi != pmi:\n",
    "                pmi = 0\n",
    "            ppmi_matrix[i, j] = max(pmi, 0)\n",
    "    target_word_seq = []\n",
    "    for word in target_words:\n",
    "        idx = w.index(word)\n",
    "        target_word_seq.append(ppmi_matrix[idx])\n",
    "    ppmi_matrix = np.vstack(target_word_seq)\n",
    "\n",
    "    U, S, Vt = np.linalg.svd(ppmi_matrix, full_matrices=False)\n",
    "\n",
    "    U_k = U[:, :dim]\n",
    "    S_k = np.diag(S[:dim])\n",
    "    Vt_k = Vt[:, :dim]\n",
    "\n",
    "    reduced_matrix = np.dot(U_k, np.dot(S_k, Vt_k))\n",
    "    return reduced_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correlation(A, B):\n",
    "    R = orthogonal_procrustes(A, B)\n",
    "    A = A @ R[0]\n",
    "    sim = cosine_similarity(A, B)\n",
    "    dist = 1 - np.diag(sim)\n",
    "    return pearsonr(dist, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim = 100\n",
      "PearsonRResult(statistic=0.11525076160435015, pvalue=0.5163038328786527) PearsonRResult(statistic=0.04565239357406478, pvalue=0.7976623962765899)\n",
      "dim = 200\n",
      "PearsonRResult(statistic=0.006080773055626997, pvalue=0.9727729126381718) PearsonRResult(statistic=-0.04068855423060658, pvalue=0.8192784052858268)\n",
      "dim = 300\n",
      "PearsonRResult(statistic=0.1192138357207263, pvalue=0.5018827338692741) PearsonRResult(statistic=-0.06974438617952483, pvalue=0.6951006204972674)\n",
      "dim = 400\n",
      "PearsonRResult(statistic=0.046080204862941704, pvalue=0.7958060632350512) PearsonRResult(statistic=-0.17522480031112073, pvalue=0.32158468516522776)\n",
      "dim = 500\n",
      "PearsonRResult(statistic=0.07633601767445748, pvalue=0.6678580028988524) PearsonRResult(statistic=-0.2039975273310748, pvalue=0.2471798345343225)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6335429487279237, -0.008104128156015954)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value = []\n",
    "correlation = []\n",
    "\n",
    "for dim in [100, 200, 300, 400, 500]:\n",
    "    ppmi_matrix_2019 = get_ppmi_by_year(2019, dim)\n",
    "    ppmi_matrix_2020 = get_ppmi_by_year(2020, dim)\n",
    "    ppmi_matrix_2021 = get_ppmi_by_year(2021, dim)\n",
    "    print(f'dim = {dim}')\n",
    "    corr_1920 = find_correlation(ppmi_matrix_2019, ppmi_matrix_2020)\n",
    "    corr_2021 = find_correlation(ppmi_matrix_2020, ppmi_matrix_2021)\n",
    "    p_value.append(corr_1920[1])\n",
    "    p_value.append(corr_2021[1])\n",
    "    correlation.append(corr_1920[0])\n",
    "    correlation.append(corr_2021[0])\n",
    "    print(corr_1920, corr_2021)\n",
    "\n",
    "sum(p_value) / len(p_value), sum(correlation) / len(correlation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "4bbd96449fffa39e361fc66bcb5d1530b80999218b6fe704e78cc8f408c31850"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
